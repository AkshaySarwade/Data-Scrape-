{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import feedparser\n",
        "import requests\n",
        "import sqlalchemy\n",
        "from sqlalchemy import create_engine, Column, String, DateTime\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from spacy.lang.en import English\n",
        "from celery import Celery\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "HHhpUb4I3pyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK data\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Database configuration\n",
        "Base = declarative_base()\n",
        "\n",
        "class Article(Base):\n",
        "    __tablename__ = 'articles'\n",
        "\n",
        "    id = Column(sqlalchemy.Integer, primary_key=True)\n",
        "    title = Column(String)\n",
        "    content = Column(String)\n",
        "    publication_date = Column(DateTime)\n",
        "    source_url = Column(String)\n",
        "    category = Column(String)"
      ],
      "metadata": {
        "id": "AEdazjht3p2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Celery\n",
        "app = Celery('tasks', broker='pyamqp://guest@localhost//')\n",
        "\n",
        "# Database configuration\n",
        "engine = create_engine('postgresql://user:password@localhost/dbname')\n",
        "Base.metadata.create_all(engine)\n",
        "Session = sessionmaker(bind=engine)\n",
        "\n",
        "# RSS Feeds\n",
        "rss_feeds = [\n",
        "    'http://rss.cnn.com/rss/cnn_topstories.rss',\n",
        "    'http://qz.com/feed',\n",
        "    'http://feeds.foxnews.com/foxnews/politics',\n",
        "    'http://feeds.reuters.com/reuters/businessNews',\n",
        "    'http://feeds.feedburner.com/NewshourWorld',\n",
        "    'https://feeds.bbci.co.uk/news/world/asia/india/rss.xml'\n",
        "]\n"
      ],
      "metadata": {
        "id": "gVe3vFlD3p53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Category classification\n",
        "nlp = English()\n",
        "\n",
        "def classify_category(text):\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
        "    if 'terrorism' in tokens or 'protest' in tokens or 'political unrest' in tokens or 'riot' in tokens:\n",
        "        return 'Terrorism / protest / political unrest / riot'\n",
        "    elif 'positive' in tokens or 'uplifting' in tokens:\n",
        "        return 'Positive/Uplifting'\n",
        "    elif 'natural disaster' in tokens or 'disasters' in tokens:\n",
        "        return 'Natural Disasters'\n",
        "    else:\n",
        "        return 'Others'\n",
        "\n",
        "# Task queue\n",
        "@app.task\n",
        "def process_article(article):\n",
        "    title = article['title']\n",
        "    content = article['summary']\n",
        "    publication_date = datetime.strptime(article['published'], '%a, %d %b %Y %H:%M:%S %z')\n",
        "    source_url = article['link']\n",
        "    category = classify_category(content)\n",
        "\n",
        "    # Store the article in the database\n",
        "    session = Session()\n",
        "    new_article = Article(title=title, content=content, publication_date=publication_date, source_url=source_url, category=category)\n",
        "    session.add(new_article)\n",
        "    session.commit()\n",
        "    session.close()\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    for feed in rss_feeds:\n",
        "        response = requests.get(feed)\n",
        "        parsed_feed = feedparser.parse(response.content)\n",
        "        for entry in parsed_feed.entries:\n",
        "            process_article.delay(entry)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "4sbfYinE33jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y22SYHfF33mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B__aTruy3p9K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}